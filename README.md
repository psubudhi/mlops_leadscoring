Steps to run the Notebooks/Pipeline

1. Pre-Requisite: Clean the data using the notebook data_cleaning_template.ipynb
	Outout: cleaned_data.csv
	Copy all the pipeline folders in /home/airflow/dags folder.
	Configure the airflow.cfg file to locate to the path of dags.
	Update Port of Airflow webserver.	
	
2.	Run the model experiments (in notebooks folder)to find the best model to be used for the training, 
	evaluation and 	
	inference. LGBM model found to be best and will be used for finding the best performance and inference.
	
3. Start MLFlow:

	root@f6d2b5df6971:~/airflow/dags/final/Lead_scoring_data_pipeline# mlflow server --backend-store-uri='sqlite:///lead_scoring_data_cleaning.db' --default-artifact-root="mlruns/" --port=6006 --host=0.0
	
4. Start Airflow Scheduler

	root@9f401a5c99c2:~# airflow scheduler
	____________       _____________
	____    |__( )_________  __/__  /________      __
	____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
	___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
	_/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
	[2024-09-06 19:20:19 +0000] [2338] [INFO] Starting gunicorn 20.1.0
	[2024-09-06 19:20:19 +0000] [2338] [INFO] Listening at: http://0.0.0.0:8793 (2338)
	[2024-09-06 19:20:19 +0000] [2338] [INFO] Using worker: sync
	[2024-09-06 19:20:19 +0000] [2339] [INFO] Booting worker with pid: 2339
	[2024-09-06 19:20:19 +0000] [2340] [INFO] Booting worker with pid: 2340
	[2024-09-06 19:20:19,590] {scheduler_job.py:708} INFO - Starting the scheduler
	[2024-09-06 19:20:19,590] {scheduler_job.py:713} INFO - Processing each file at most -1 times
	[2024-09-06 19:20:19,593] {executor_loader.py:105} INFO - Loaded executor: SequentialExecutor
	[2024-09-06 19:20:19,600] {manager.py:160} INFO - Launched DagFileProcessorManager with pid: 2341
	[2024-09-06 19:20:19,602] {scheduler_job.py:1233} INFO - Resetting orphaned tasks for active dag runs
	[2024-09-06 19:20:19,618] {settings.py:55} INFO - Configured default timezone Timezone('UTC')
	[2024-09-06 19:20:19,621] {scheduler_job.py:1256} INFO - Marked 1 SchedulerJob instances as failed
	[2024-09-06 19:20:19,639] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.

5. Start Airflow Webserver.

	root@e6326b3a7375:~# airflow webserver --port 6007
	____________       _____________
	____    |__( )_________  __/__  /________      __
	____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
	___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
	_/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
	Running the Gunicorn Server with:
	Workers: 4 sync
	Host: 0.0.0.0:6007
	Timeout: 120
	Logfiles: - -
	Access Logformat: 
	=================================================================
	[2024-09-05 08:30:09 +0000] [2241] [INFO] Starting gunicorn 20.1.0
	[2024-09-05 08:30:10 +0000] [2241] [INFO] Listening at: http://0.0.0.0:6007 (2241)
	[2024-09-05 08:30:10 +0000] [2241] [INFO] Using worker: sync
	[2024-09-05 08:30:10 +0000] [2243] [INFO] Booting worker with pid: 2243
	[2024-09-05 08:30:10 +0000] [2244] [INFO] Booting worker with pid: 2244
	[2024-09-05 08:30:10 +0000] [2245] [INFO] Booting worker with pid: 2245
	[2024-09-05 08:30:10 +0000] [2246] [INFO] Booting worker with pid: 2246

6. Run the DAG from Airflow UI lead_scoring_model_experimentation.ipynb	

7. Runt unit test (pytest)
	pytest test_with_pytest.py
	Run log of this test is in unit_test/run_logs.txt
	
8. Run the pipeline in below order from airflow ui:
	lead_scoring_data_pipeline
	lead_scoring_training_pipeline	
	lead_scoring_inference_pipeline
		genrerate prediction distribution.

9 All the screenshots of the mlflow ui and its artifacts are pasted in ScreenShots_DAG_MLFlow.pdf file.
   note: the screenshot of artifacts generated by DAG could not be generated, Upgrad team tried hard bit could not reslove it till now ( more then a 45 days followed up to fix this issue) so submitting this asignment with out this screenshot.
   
   
Many issues encountered, I am unable to proceed further because of below issue(2 months followup with Upgrad team, not solution found) , besides above artifact at MLflow.

Ooops!
Something bad has happened.

Airflow is used by many users, and it is very likely that others had similar problems and you can easily find
a solution to your problem.

Consider following these steps:

  * gather the relevant information (detailed logs with errors, reproduction steps, details of your deployment)

  * find similar issues using:
     * GitHub Discussions
     * GitHub Issues
     * Stack Overflow
     * the usual search engine you use on a daily basis

  * if you run Airflow on a Managed Service, consider opening an issue using the service support channels

  * if you tried and have difficulty with diagnosing and fixing the problem yourself, consider creating a bug report.
    Make sure however, to include all relevant details and results of your investigation so far.

Python version: 3.8.12
Airflow version: 2.3.3
Node: f6d2b5df6971
-------------------------------------------------------------------------------
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/flask/app.py", line 2073, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.8/site-packages/flask/app.py", line 1519, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/opt/conda/lib/python3.8/site-packages/flask/app.py", line 1517, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.8/site-packages/flask/app.py", line 1503, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)
  File "/opt/conda/lib/python3.8/site-packages/airflow/www/auth.py", line 46, in decorated
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/airflow/www/views.py", line 964, in index
    return self.render_template(
  File "/opt/conda/lib/python3.8/site-packages/airflow/www/views.py", line 709, in render_template
    return super().render_template(
  File "/opt/conda/lib/python3.8/site-packages/flask_appbuilder/baseviews.py", line 322, in render_template
    return render_template(
  File "/opt/conda/lib/python3.8/site-packages/flask/templating.py", line 154, in render_template
    return _render(
  File "/opt/conda/lib/python3.8/site-packages/flask/templating.py", line 128, in _render
    rv = template.render(context)
  File "/opt/conda/lib/python3.8/site-packages/jinja2/environment.py", line 1291, in render
    self.environment.handle_exception()
  File "/opt/conda/lib/python3.8/site-packages/jinja2/environment.py", line 925, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "/opt/conda/lib/python3.8/site-packages/airflow/www/templates/airflow/dags.html", line 43, in top-level template code
    {% elif curr_ordering_direction == 'asc' and request.args.get('sorting_key') == attribute_name %}
  File "/opt/conda/lib/python3.8/site-packages/airflow/www/templates/airflow/main.html", line 21, in top-level template code
    {% from 'airflow/_messages.html' import show_message %}
  File "/opt/conda/lib/python3.8/site-packages/flask_appbuilder/templates/appbuilder/baselayout.html", line 2, in top-level template code
    {% import 'appbuilder/baselib.html' as baselib %}
  File "/opt/conda/lib/python3.8/site-packages/flask_appbuilder/templates/appbuilder/init.html", line 37, in top-level template code
    {% block body %}
  File "/opt/conda/lib/python3.8/site-packages/flask_appbuilder/templates/appbuilder/baselayout.html", line 16, in block 'body'
    {% block messages %}
  File "/opt/conda/lib/python3.8/site-packages/airflow/www/templates/airflow/dags.html", line 104, in block 'messages'
    {{ super() }}
  File "/opt/conda/lib/python3.8/site-packages/airflow/www/templates/airflow/main.html", line 62, in block 'messages'
    {% call show_message(category='warning', dismissible=false) %}
  File "/opt/conda/lib/python3.8/site-packages/jinja2/runtime.py", line 828, in _invoke
    rv = self._func(*arguments)
  File "/opt/conda/lib/python3.8/site-packages/airflow/www/templates/airflow/_messages.html", line 25, in template
    {{ caller() }}
  File "/opt/conda/lib/python3.8/site-packages/jinja2/runtime.py", line 828, in _invoke
    rv = self._func(*arguments)
  File "/opt/conda/lib/python3.8/site-packages/airflow/www/templates/airflow/main.html", line 70, in template
    >{{ macros.datetime_diff_for_humans(scheduler_job.latest_heartbeat) }}</time>.
  File "/opt/conda/lib/python3.8/site-packages/airflow/macros/__init__.py", line 77, in datetime_diff_for_humans
    return pendulum.instance(dt).diff_for_humans(since)
  File "/opt/conda/lib/python3.8/site-packages/pendulum/datetime.py", line 824, in diff_for_humans
    other = self.now()
  File "/opt/conda/lib/python3.8/site-packages/pendulum/datetime.py", line 106, in now
    return pendulum.now(tz)
  File "/opt/conda/lib/python3.8/site-packages/pendulum/__init__.py", line 211, in now
    dt = _datetime.datetime.now(local_timezone())
  File "/opt/conda/lib/python3.8/site-packages/pendulum/tz/__init__.py", line 60, in local_timezone
    return get_local_timezone()
  File "/opt/conda/lib/python3.8/site-packages/pendulum/tz/local_timezone.py", line 35, in get_local_timezone
    tz = _get_system_timezone()
  File "/opt/conda/lib/python3.8/site-packages/pendulum/tz/local_timezone.py", line 63, in _get_system_timezone
    return _get_unix_timezone()
  File "/opt/conda/lib/python3.8/site-packages/pendulum/tz/local_timezone.py", line 242, in _get_unix_timezone
    raise RuntimeError("Unable to find any timezone configuration")
RuntimeError: Unable to find any timezone configuration